<!doctype html>
<!--[if lt IE 7]><html class="no-js lt-ie9 lt-ie8 lt-ie7" lang="en"> <![endif]-->
<!--[if (IE 7)&!(IEMobile)]><html class="no-js lt-ie9 lt-ie8" lang="en"><![endif]-->
<!--[if (IE 8)&!(IEMobile)]><html class="no-js lt-ie9" lang="en"><![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en"><!--<![endif]-->
<head>
<meta charset="utf-8">
<title>Relation Extraction with Matrix Factorization &#8211; Yanran's Attic</title>
<meta name="description" content="Natural Language Processing, Semantic Embedding, Machine learning, deep learning">
<meta name="keywords" content="matrix factorization, relation extraction">



<!-- Open Graph -->
<meta property="og:locale" content="en_US">
<meta property="og:type" content="article">
<meta property="og:title" content="Relation Extraction with Matrix Factorization">
<meta property="og:description" content="Natural Language Processing, Semantic Embedding, Machine learning, deep learning">
<meta property="og:url" content="http://yanran.li/naturallanguageprocessing/2013/11/11/Relation-Extraction-with-Matrix-Factorization.html">
<meta property="og:site_name" content="Yanran's Attic">





<link rel="canonical" href="http://yanran.li/naturallanguageprocessing/2013/11/11/Relation-Extraction-with-Matrix-Factorization.html">
<link href="http://yanran.li/feed.xml" type="application/atom+xml" rel="alternate" title="Yanran's Attic Feed">


<!-- http://t.co/dKP3o1e -->
<meta name="HandheldFriendly" content="True">
<meta name="MobileOptimized" content="320">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<!-- For all browsers -->
<link rel="stylesheet" href="http://yanran.li/assets/css/main.min.css">
<!-- Webfonts -->
<link href="http://fonts.googleapis.com/css?family=Lato:300,400,700,300italic,400italic" rel="stylesheet" type="text/css">

<meta http-equiv="cleartype" content="on">

<!-- Load Modernizr -->
<script src="http://yanran.li/assets/js/vendor/modernizr-2.6.2.custom.min.js"></script>

<!-- Icons -->
<!-- 16x16 -->
<link rel="shortcut icon" href="http://yanran.li/images/favicon.ico">
<!-- 32x32 -->
<link rel="shortcut icon" href="http://yanran.li/images/favicon.png">
<!-- 57x57 (precomposed) for iPhone 3GS, pre-2011 iPod Touch and older Android devices -->
<link rel="apple-touch-icon-precomposed" href="http://yanran.li/images/favicon.png">
<!-- 72x72 (precomposed) for 1st generation iPad, iPad 2 and iPad mini -->
<link rel="apple-touch-icon-precomposed" sizes="72x72" href="http://yanran.li/images/favicon.png">
<!-- 114x114 (precomposed) for iPhone 4, 4S, 5 and post-2011 iPod Touch -->
<link rel="apple-touch-icon-precomposed" sizes="114x114" href="http://yanran.li/images/favicon.png">
<!-- 144x144 (precomposed) for iPad 3rd and 4th generation -->
<link rel="apple-touch-icon-precomposed" sizes="144x144" href="http://yanran.li/images/favicon.png">
<link rel="shortcut icon" href="/images/favicon.ico"/>
<link rel="bookmark" href="/images/favicon.ico"/>



<!-- MathJax -->
<script type="text/javascript"
src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>




<script type="text/javascript"
src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>

</head>

<body id="post" >

<!--[if lt IE 9]><div class="upgrade"><strong><a href="http://whatbrowser.org/">Your browser is quite old!</strong> Why not upgrade to a different browser to better enjoy this site?</a></div><![endif]-->
<nav id="dl-menu" class="dl-menuwrapper" role="navigation">
	<button class="dl-trigger">Open Menu</button>
	<ul class="dl-menu">
		<li><a href="http://yanran.li">Home</a></li>
		<li>
			<a href="#">About</a>
			<ul class="dl-submenu">
				<li>
					<img src="http://yanran.li/images/avatar.jpg" alt="Yanran Li photo" class="author-photo">
					<h4>Yanran Li</h4>
					<p>Research Assistant at PolyU</p>
				</li>
				<li><a href="http://yanran.li/about/">Learn More</a></li>
				<li>
					<a href="mailto:yanranli.summer@gmail.com"><i class="icon-envelope"></i> Email</a>
				</li>
				
				
				<li>
					<a href="http://weibo.com/summerrlee"><i class="icon-weibo"></i> Weibo</a>
				</li>
				
				<li>
					<a href="https://www.linkedin.com/profile/view?id=233043238"><i class="icon-linkedin"></i> LinkedIn</a>
				</li>
				<li>
					<a href="http://github.com/niangaotuantuan"><i class="icon-github-alt"></i> GitHub</a>
				</li>
				
				
				
				
<!-- 				 -->
			</ul><!-- /.dl-submenu -->
		</li>
		<li>
			<a href="#">Posts</a>
			<ul class="dl-submenu">
				<li><a href="http://yanran.li/posts/">All Posts</a></li>
				<li><a href="http://yanran.li/categories/">All Categories</a></li>			
				<li><a href="http://yanran.li/tags/">All Tags</a></li>			
			</ul>
		</li>
		<li><a href="http://yanran.li/categories/#peppypapers">PaperNotes</a></li><li><a href="http://yanran.li/guestbook">GuestBook</a></li><li><a href="http://yanran.li/friends">Friends</a></li><li><a href="https://web.cs.dal.ca/~vlado/nlp/" class="external">NLP links</a></li><li><a href="http://www.reddit.com/r/machinelearning" class="external">r/machinelearning</a></li><li><a href="https://plus.google.com/communities/112866381580457264725" class="external">Deep Learning G+</a></li>
	</ul><!-- /.dl-menu -->
</nav><!-- /.dl-menuwrapper -->




<div id="main" role="main">
  <article class="hentry">
    <header class="header-title">
      <div class="header-title-wrap">
        
          <h1 class="entry-title"><a href="http://yanran.li/naturallanguageprocessing/2013/11/11/Relation-Extraction-with-Matrix-Factorization.html" rel="bookmark" title="Relation Extraction with Matrix Factorization">Relation Extraction with Matrix Factorization</a></h1>
        
        <h2>November 11, 2013</h2>
      </div><!-- /.header-title-wrap -->
    </header>
    <div class="entry-content">
      <p>This post is about the NAACL’13 Accepted Paper, <strong>Relation Extraction with Matrix Factorization and Universal Schemas</strong>. The talk is available on <a href="http://techtalks.tv/talks/relation-extraction-with-matrix-factorization-and-universal-schemas/58435/">techtalks</a>.</p>

<p>And then present some basic knowledge of <strong>Matrix Factorization</strong>. </p>

<h2 id="abstract">Abstract</h2>

<p>The paper studies techniques for inferring a model of entities and relations capable of performing basic types of semantic inference (e.g., predicting if a specific relation holds for a given pair of entities). The models exploit different types of embeddings of entities and relations.  </p>

<p>This problem is usually tackled either via distant weak supervision from a knowledge base (providing structure and relational schemas) or in a totally unsupervised fashion (without any pre-defined schemas). The present approach aims at combining both trends with the introduction of universal schemas that can blend pre-defined ones from knowledge bases and uncertain ones extracted from free text.  This paper is very ambitious and interesting. </p>

<h2 id="related-work">Related Work</h2>

<h3 id="relation-extraction">relation extraction</h3>

<p>There has been a lot of previous research on learning entailment (aka inference) rules (e.g., Chkolvsky and Pantel 2004; Berant et al, ACL 2011; Nakashole et al, ACL 2012). 
Also, there has been some of the very related work on embedding relations, e.g., Bordes et al (AAAI 2011), or, very closely related, Jenatton et al (NIPS 2012).</p>

<h3 id="matrix-factorization">Matrix Factorization</h3>

<p><strong>Matrix factorization</strong> as a technique of <em>Collaborative filtering</em> has been the
preferred choice for recommendation systems ever since Netflix million competition was held a few years back. Further, with the advent of news personalization, advanced search and user analytics, the concept has gained
prominence.</p>

<p>In this paper, columns correspond to relations, and rows correspond to entity tuples. By contrast, in (Murphy et al., 2012) columns are words, and rows
are contextual features such as “words in a local window.” Consequently, this paper’s objective is to complete the matrix, whereas their objective is to learn better latent embeddings of words (which by themselves again cannot capture any sense of asymmetry).</p>

<h2 id="save-storage">Save Storage</h2>

<p>Although the paper doesn’t explicit point out how common is it that a tuple shares many relations, it remains concern. The experiments seem to show that mixing data sources is beneficial. </p>

<h2 id="trends">Trends</h2>

<p>The researchers are ambitious to bridge knowledges bases and text for information extraction, and this paper seems to go along this trend.
However, the paper’s scheme is limited before complex named entity disambiguation is solved, since it relies on the fact that entities constituting tuples from the Freebase and tuples extracted from the text have been exactly matched beforehand.</p>

<h2 id="generalized-matrix-factorization">Generalized Matrix Factorization</h2>

<p>It has been a general machine learning problem formulated as:</p>

<h3 id="training-data">Training data</h3>
<ul>
  <li><strong>V</strong>: m x n input matrix (e.g., rating matrix)</li>
  <li>Z: training set of indexes in <strong>V</strong> (e.g., subset of known ratings)</li>
</ul>

<h3 id="parameter-space">Parameter space</h3>
<ul>
  <li><strong>W</strong>: row factors (e.g., m x r latent customer factors)</li>
  <li><strong>H</strong>: column factors (e.g., r x n latent movie factors)</li>
</ul>

<h3 id="model">Model</h3>
<ul>
  <li><script type="math/tex"> L_{ij}(W_{i*},H_{*j}) </script>: loss at element (<em>i</em>,<em>j</em>)</li>
  <li>Includes prediction error, regularization, auxiliary information, . . .</li>
  <li>Constraints (e.g., non-negativity)</li>
</ul>

<h3 id="find-best-model">Find best model</h3>

<script type="math/tex; mode=display"> \arg\min_{W,H}\sum_{(i,j)\in Z}L_{i,j}(W_{i*},H_{*j}) </script>

<h2 id="stochastic-gradient-descent-for-matrix-factorization">Stochastic Gradient Descent for Matrix Factorization</h2>

<p>Among the various algorithmic techniques available, the following are more
popular: <strong>Alternating Least Squares (ALS)</strong>， <strong>Non-Negative Matrix Factorization</strong> and <strong>Stochastic Gradient Descent (SGD)</strong>. Here I only presents SGD for MF.</p>

<p><strong>SDG</strong> is a well know technique which tends to compute direction of steepest descent and then takes a step in that direction. Among the variants include:</p>

<p>(a)Partitioned SGD: distribute without using stratification and run independently and in parallel on partitions (b)Pipelined SGD: based on ‘delayed update’ scheme (c)Decentralized SGD: computation in decentralized and distributed fashion</p>

<p>The main solution is as follows:</p>

<ul>
  <li>
    <p>Set <script type="math/tex"> \theta = (W,H) </script> and use</p>

    <p><script type="math/tex"> L(\theta)=\sum_{(i,j)\in Z}L_{ij}(W_{i*},H_{*j}) </script>,  <br />
  <script type="math/tex"> {L}'(\theta)=\sum_{(i,j)\in Z}{L}'_{ij}(W_{i*},H_{*j}) </script>,  <br />
  <script type="math/tex"> {\hat{L}}'(\theta,z)=N{L}'_{i_{z}j_{z}}(W_{i_{z}*},H_{*j_{z}}) </script>, where <script type="math/tex">N=\vert Z\vert</script></p>
  </li>
  <li>
    <p>SGD epoch</p>
    <ul>
      <li>Pick a random entry <script type="math/tex"> z \in Z </script></li>
      <li>Compute approximate gradient <script type="math/tex"> {\hat{L}}'(\theta,z) </script></li>
      <li>Update parameters <script type="math/tex"> \theta_{n+1}=\theta_{n}-\epsilon_{n}{\hat{L}}'(\theta,z) </script></li>
      <li>Repeat <script type="math/tex">N</script> times</li>
    </ul>
  </li>
</ul>

<h2 id="svm-vs-fm">SVM V.S. FM</h2>

<p><strong>FM</strong> is short for <a href="http://www.libfm.org/"><strong>Factorization Machine</strong></a>. Indeed, it can be interpreted as <strong>Factorization</strong> Methods and Support Vector <strong>Machine</strong>. It is firstly published by Steffen Rendle. </p>

<p>Factorization machines (FM) are a generic approach that allows to mimic most factorization models by feature engineering. This way, factorization machines combine the generality of feature engineering with the superiority of factorization models in estimating interactions between categorical variables of large domain. libFM is a software implementation for factorization machines that features stochastic gradient descent (SGD) and alternating least squares (ALS) optimization as well as Bayesian inference using Markov Chain Monte Carlo (MCMC).</p>

<p><img src="http://i.imgur.com/Kc7q9Pl.png" alt="" /></p>

<p>in SVM mode, <script type="math/tex"> y(x)=w\cdot x+b=w_{u}+w_{i}+...+b=\sum w_{i}x_{i}+b </script>, but original SVM fails with 2 main problems using here: <em>Real Value V.S. Classification</em>, and <em>Sparsity</em>.</p>

<p>in Factorization Machine mode, it is solved as: <script type="math/tex"> y(x)=\sum w_{i}x_{i}+\sum\sum(v_{i}\cdot v_{j})x_{i}x_{j} +b </script>. The second part in the formula is <strong>Factorization</strong>, where the transformation from original SVM to FM lies.</p>

<p><img src="http://i.imgur.com/bgOUxWh.png" alt="" />
<img src="http://i.imgur.com/eHhxEsb.png" alt="" /></p>

<h2 id="fm-vs-mf">FM V.S. MF</h2>

<ul>
  <li>FM: <script type="math/tex"> y(x)=\sum w_{i}x_{i}+\sum\sum(v_{i}\cdot v_{j})x_{i}x_{j} +b </script></li>
  <li>MF: <script type="math/tex"> y(x)=w_{u}+w_{i}+v_{u}\cdot v_{i} + b </script></li>
</ul>


      <footer class="entry-meta">
        <span class="entry-tags"><a href="http://yanran.li/tags/#matrix factorization" title="Pages tagged matrix factorization" class="tag">matrix factorization</a><a href="http://yanran.li/tags/#relation extraction" title="Pages tagged relation extraction" class="tag">relation extraction</a></span>
        <span><a href="http://yanran.li/naturallanguageprocessing/2013/11/11/Relation-Extraction-with-Matrix-Factorization.html" rel="bookmark" title="Relation Extraction with Matrix Factorization">Relation Extraction with Matrix Factorization</a> was published on <span class="entry-date date published updated"><time datetime="2013-11-11T00:00:00+08:00">November 11, 2013</time></span></span>
        
        <span class="author vcard"><span class="fn"><a href="http://yanran.li/about/" title="About Yanran Li">Yanran Li</a></span></span>
        <div class="social-share">
          <ul class="socialcount socialcount-small inline-list">
            <li class="facebook"><a href="https://www.facebook.com/sharer/sharer.php?u=http://yanran.li/naturallanguageprocessing/2013/11/11/Relation-Extraction-with-Matrix-Factorization.html" title="Share on Facebook"><span class="count"><i class="icon-facebook-sign"></i> Like</span></a></li>
            <li class="twitter"><a href="https://twitter.com/intent/tweet?text=http://yanran.li/naturallanguageprocessing/2013/11/11/Relation-Extraction-with-Matrix-Factorization.html" title="Share on Twitter"><span class="count"><i class="icon-twitter-sign"></i> Tweet</span></a></li>
            <li class="googleplus"><a href="https://plus.google.com/share?url=http://yanran.li/naturallanguageprocessing/2013/11/11/Relation-Extraction-with-Matrix-Factorization.html" title="Share on Google Plus"><span class="count"><i class="icon-google-plus-sign"></i> +1</span></a></li>
          </ul>
        </div><!-- /.social-share -->
      </footer>
    </div><!-- /.entry-content -->
    <section id="disqus_thread"></section><!-- /#disqus_thread -->
    
    <div class="read-more">
      
        <div class="read-more-header">
          <a href="http://yanran.li/peppypapers/2013/10/05/incorporating-domain-knowledge-into-LDA.html" class="read-more-btn">Read More</a>
        </div><!-- /.read-more-header -->
        <div class="read-more-content">
          <h3><a href="http://yanran.li/peppypapers/2015/04/18/DeepWalk-Online-Learning-of-Social-Representations.html" title="DeepWalk Online Learning of Social Representations">DeepWalk Online Learning of Social Representations</a></h3>
          <p>这是一篇我个人非常喜欢的论文，不仅提出了一个想法，更展示了这个想法的可行性和可能空间。提出的想法是利用网络结构信息将用户表示为低维实值向量，学出来的表示是最重要的，因为有了表示就可以用来加在许多其他任务上。 <a href="http://yanran.li/peppypapers/2015/04/18/DeepWalk-Online-Learning-of-Social-Representations.html">Continue reading</a></p>
        </div><!-- /.read-more-content -->
      
      <div class="read-more-list">
        
          <div class="list-item">
            <h4><a href="http://yanran.li/machinelearning/2015/04/17/collections-of-tips-for-machine-learning.html" title="Collections of Tips for Machine Learning">Collections of Tips for Machine Learning</a></h4>
            <span>Published on April 17, 2015</span>
          </div><!-- /.list-item -->
        
          <div class="list-item">
            <h4><a href="http://yanran.li/life/2015/04/15/how-i-manage-my-knowledge.html" title="我是这样进行知识管理的">我是这样进行知识管理的</a></h4>
            <span>Published on April 15, 2015</span>
          </div><!-- /.list-item -->
        
      </div><!-- /.read-more-list -->
      
    </div><!-- /.read-more -->
  </article>
</div><!-- /#main -->

<div class="footer-wrapper">
  <footer role="contentinfo">
    <span>&copy; 2015 Yanran Li. Powered by <a href="http://jekyllrb.com">Jekyll</a> using the <a href="http://mademistakes.com/hpstr/">HPSTR Theme</a>.</span>
  </footer>
</div><!-- /.footer-wrapper -->

<script src="//ajax.googleapis.com/ajax/libs/jquery/1.9.1/jquery.min.js"></script>
<script>window.jQuery || document.write('<script src="http://yanran.li/assets/js/vendor/jquery-1.9.1.min.js"><\/script>')</script>
<script src="http://yanran.li/assets/js/scripts.min.js"></script>

<script type="text/javascript">
    /* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
    var disqus_shortname = 'yanranli'; // required: replace example with your forum shortname

    /* * * DON'T EDIT BELOW THIS LINE * * */
    (function() {
        var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
        dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();

    /* * * DON'T EDIT BELOW THIS LINE * * */
    (function () {
        var s = document.createElement('script'); s.async = true;
        s.type = 'text/javascript';
        s.src = '//' + disqus_shortname + '.disqus.com/count.js';
        (document.getElementsByTagName('HEAD')[0] || document.getElementsByTagName('BODY')[0]).appendChild(s);
    }());
</script>
<noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="http://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>	        

</body>
</html>
