<!doctype html>
<!--[if lt IE 7]><html class="no-js lt-ie9 lt-ie8 lt-ie7" lang="en"> <![endif]-->
<!--[if (IE 7)&!(IEMobile)]><html class="no-js lt-ie9 lt-ie8" lang="en"><![endif]-->
<!--[if (IE 8)&!(IEMobile)]><html class="no-js lt-ie9" lang="en"><![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en"><!--<![endif]-->
<head>
<meta charset="utf-8">
<title>Adapations and Variations of Word2vec &#8211; Maggie's KingDom</title>
<meta name="description" content="word2vec 中考虑的是 linear 的 bag-of-words contexts。分三点来看：linear、bag-of-words、contexts。linear 强调的就是 plain，没有额外 word-level 以外的信息的，比如 syntax，比如 relation，比如 anything you can imagine；bag-of-words 强调的是 non-ordered，也就是说，词袋模型，这个 word2vec 是没有考虑语序的；第三个是 contexts，一方面是说，word2vec 只能考虑上下文信息（没有考虑词汇内部或者更高的 global/document-level 信息），另一方面是说，这个 contexts 也是被 window size 框住大小的，导致太大的 size computational cost 太大；太小的 size 又不能 handle 足够的信息，同时也会容易出现很多不想出现的词和想出现但没出现的词。">
<meta name="keywords" content="deep learning, natural language processing, representaion, word2vec, paper">



<!-- Open Graph -->
<meta property="og:locale" content="en_US">
<meta property="og:type" content="article">
<meta property="og:title" content="Adapations and Variations of Word2vec">
<meta property="og:description" content="word2vec 中考虑的是 linear 的 bag-of-words contexts。分三点来看：linear、bag-of-words、contexts。linear 强调的就是 plain，没有额外 word-level 以外的信息的，比如 syntax，比如 relation，比如 anything you can imagine；bag-of-words 强调的是 non-ordered，也就是说，词袋模型，这个 word2vec 是没有考虑语序的；第三个是 contexts，一方面是说，word2vec 只能考虑上下文信息（没有考虑词汇内部或者更高的 global/document-level 信息），另一方面是说，这个 contexts 也是被 window size 框住大小的，导致太大的 size computational cost 太大；太小的 size 又不能 handle 足够的信息，同时也会容易出现很多不想出现的词和想出现但没出现的词。">
<meta property="og:url" content="/peppypapers/2015/05/23/Adapations-and-Variations-of-Word2Vec.html">
<meta property="og:site_name" content="Maggie's KingDom">





<link rel="canonical" href="/peppypapers/2015/05/23/Adapations-and-Variations-of-Word2Vec.html">
<link href="/feed.xml" type="application/atom+xml" rel="alternate" title="Maggie's KingDom Feed">


<!-- http://t.co/dKP3o1e -->
<meta name="HandheldFriendly" content="True">
<meta name="MobileOptimized" content="320">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<!-- For all browsers -->
<link rel="stylesheet" href="/assets/css/main.min.css">
<!-- Webfonts -->
<link href="http://fonts.googleapis.com/css?family=Lato:300,400,700,300italic,400italic" rel="stylesheet" type="text/css">

<meta http-equiv="cleartype" content="on">

<!-- Load Modernizr -->
<script src="/assets/js/vendor/modernizr-2.6.2.custom.min.js"></script>

<!-- Icons -->
<!-- 16x16 -->
<link rel="shortcut icon" href="/images/favicon.ico">
<!-- 32x32 -->
<link rel="shortcut icon" href="/images/favicon.png">
<!-- 57x57 (precomposed) for iPhone 3GS, pre-2011 iPod Touch and older Android devices -->
<link rel="apple-touch-icon-precomposed" href="/images/favicon.png">
<!-- 72x72 (precomposed) for 1st generation iPad, iPad 2 and iPad mini -->
<link rel="apple-touch-icon-precomposed" sizes="72x72" href="/images/favicon.png">
<!-- 114x114 (precomposed) for iPhone 4, 4S, 5 and post-2011 iPod Touch -->
<link rel="apple-touch-icon-precomposed" sizes="114x114" href="/images/favicon.png">
<!-- 144x144 (precomposed) for iPad 3rd and 4th generation -->
<link rel="apple-touch-icon-precomposed" sizes="144x144" href="/images/favicon.png">
<link rel="shortcut icon" href="/images/favicon.ico"/>
<link rel="bookmark" href="/images/favicon.ico"/>



<!-- MathJax -->
<script type="text/javascript"
src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>




<script type="text/javascript"
src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>

</head>

<body id="post" class="feature">

<!--[if lt IE 9]><div class="upgrade"><strong><a href="http://whatbrowser.org/">Your browser is quite old!</strong> Why not upgrade to a different browser to better enjoy this site?</a></div><![endif]-->
<nav id="dl-menu" class="dl-menuwrapper" role="navigation">
	<button class="dl-trigger">Open Menu</button>
	<ul class="dl-menu">
		<li><a href="">Home</a></li>
		<li>
			<a href="#">About</a>
			<ul class="dl-submenu">
				<li>
					<img src="/images/avatar.jpg" alt="Maggie photo" class="author-photo">
					<h4>Maggie</h4>
					<p>COMP at PolyU</p>
				</li>
				<li><a href="/about/">Learn More</a></li>
				<li>
					<a href="mailto:yanranli.summer@gmail.com"><i class="icon-envelope"></i> Email</a>
				</li>
				
				
				
				
				
				<li>
					<a href="http://github.com/wjlkingdom"><i class="icon-github-alt"></i> GitHub</a>
				</li>
				
				
				
				
<!-- 				 -->
			</ul><!-- /.dl-submenu -->
		</li>
		<li>
			<a href="#">Posts</a>
			<ul class="dl-submenu">
				<li><a href="/posts/">All Posts</a></li>
				<li><a href="/categories/">All Categories</a></li>			
				<li><a href="/tags/">All Tags</a></li>			
			</ul>
		</li>
		<li><a href="/categories/#resource">Resources</a></li><li><a href="/categories/#paper">Papers</a></li><li><a href="https://web.cs.dal.ca/~vlado/nlp/" class="external">NLP links</a></li><li><a href="http://www.reddit.com/r/machinelearning" class="external">r/machinelearning</a></li><li><a href="https://plus.google.com/communities/112866381580457264725" class="external">Deep Learning G+</a></li>
	</ul><!-- /.dl-menu -->
</nav><!-- /.dl-menuwrapper -->



<div class="entry-header">
  
  <div class="entry-image">
    <img src="/images/MultipleVectorWordEmbedding_bg.png" alt="Adapations and Variations of Word2vec">
  </div><!-- /.entry-image -->
</div><!-- /.entry-header -->


<div id="main" role="main">
  <article class="hentry">
    <header class="header-title">
      <div class="header-title-wrap">
        
          <h1 class="entry-title"><a href="/peppypapers/2015/05/23/Adapations-and-Variations-of-Word2Vec.html" rel="bookmark" title="Adapations and Variations of Word2vec">Adapations and Variations of Word2vec</a></h1>
        
        <h2>May 23, 2015</h2>
      </div><!-- /.header-title-wrap -->
    </header>
    <div class="entry-content">
      <p>word2vec 作为一个已经被广为流传的工具，其优点已不必多说。那么它有什么缺陷和不足呢？其实其作者 Mikolov 是一个非常典型的工程型选手，实用主义，什么简单方便有效就用什么；导致 word2vec 作为一个简单的模型，其忽略了很多文本中的其他信息。那么这些其他信息都有什么呢？</p>

<p>word2vec 中考虑的是 linear 的 bag-of-words contexts。这里面，分三点来看：<strong>linear、bag-of-words、contexts</strong>。linear 强调的就是 plain，没有额外 word-level 以外的信息的，比如 syntax，比如 relation，比如 anything you can imagine；bag-of-words 强调的是 non-ordered，也就是说，词袋模型，这个 word2vec 是没有考虑语序的——会丢失很多信息。第三个是 contexts，一方面是说，word2vec 只能考虑上下文信息（没有考虑词汇内部或者更高的 global/document-level 信息），另一方面是说，这个 contexts 也是被 window size 框住大小的，导致太大的 size computational cost 太大；太小的 size 又不能 handle 足够的信息，同时也会容易出现很多不想出现的词和想出现但没出现的词。</p>

<p>举个这方面论文中的经典例子，比如下面这句话：</p>

<blockquote>
  <p>“Australian scientist discovers star with telescope”  </p>
</blockquote>

<p>Note that a context window of size 2 may miss some important contexts (<em>telescope</em> is not a context of <em>discovers</em>), while including some accidental ones (<em>Australian</em> is a context <em>discovers</em>). Moreover, the contexts are unmarked, resulting in discovers being a context of both <em>stars</em> and <em>scientist</em>, which may result in stars and scientists ending up as neighbours in the embedded space. A window size of 5 is commonly used to capture broad topical content, whereas smaller windows contain more focused information about the target word. </p>

<p>就是说，当我们考虑中心词 discover 时，一个常用的窗口大小2，可能就丢失了重要的 telescope 词作为上下文，同时又加入了不相关的 Australian 这个词。这就是一种我们不想要的噪音。因为其实这个窗口的上下文是假设，这些窗口里的词，应该更在 semantic space 中聚合在一起。</p>

<p>所以，后续的研究者们分别从这几个方面（<strong>linear、bag-of-words、contexts</strong>）做出了改进（虽然他们没有明确说，但我是这样领会精神的）。</p>

<p><strong>(1)linear</strong></p>

<p><img src="/images/structure_w2v.png" alt="Two Adaptions of Word2vec" /></p>

<p>打破 linear 的方法，对于 NLPer 来说，首先就会想到加入 dependency relation，使用已经比较成熟的 dependency parsing（比如 Stanford 的工具），就可以很快引入各种语法树结构，既多了non-linear 的 relation 关系，又有了更多的 tag 作为额外信息，而且还有很顺手的工具包。这方面的工作主要有：</p>

<p>[1] Omer Levy and Yoav Goldberg. 2014. <strong>Dependency based word embeddings</strong>. In Proceedings of ACL.</p>

<p>[2] Wang Ling, Chris Dyer, Alan Black, and Isabel Trancoso. 2015. <strong>Two/too simple adaptations of word2vec for syntax problems</strong>. In Proc. of NAACL.</p>

<p>[3] Mohit Bansal, Kevin Gimpel, Karen Livescu. 2014. <strong>Tailoring Continuous Word Representations for Dependency Parsing</strong>. ACL.</p>

<p>总结他们的思想，主要是将抽取好的 dependency relation 或者其他 relation 和 信息，表达成 modifier-relation/tag 的 pair，这个 pair 作为新的 context，替代原先 word2vec 中的 context 信息。</p>

<p><strong>（2）bag-of-words</strong></p>

<p><img src="/images/dssm.png" alt="The DSSM arthitecture" /></p>

<p>bag-of-words 可以说不仅有 non-order 的问题，还有 words 的问题。也就是说，现在的工作是基于 word/token level 去做的，但实际上已经有不少人质疑这点，认为 character-level 的信息足够可以当做 input 输入。对于 non-order 方面，有人提出了用多个 embedding matrix 来增强 word2vec 中的 同一个 embedding matrix，从而使得原始的 context 位置信息可以保留；而其实刚才上面 linear 增强部分提到的 dependency pair 的方法也可以看做是保留了 order。而，关于 word-level 的问题，很多人虽然考虑了 morpheme 层面的信息，但不能算是直接替代 word-level input；相反，MSR 的 Deep Learning 组，由 Jianfeng Gao 等人 lead 的 DSSM （Deep Structured Semantic Model or Deep Semantic Similarity Model）则提倡从 Sub-Word Unit （SWU）的层面进行输入。相关工作可见：</p>

<p>[4] Mikolov Tomáš, Sutskever Ilya, Deoras Anoop, Le Hai-Son, Kombrink Stefan, Černocký Jan. <strong>Subword Language Modeling with Neural Networks</strong>. Not published (rejected from ICASSP 2012).</p>

<p>[5] Omer Levy and Yoav Goldberg. 2014. <strong>Dependency based word embeddings</strong>. In Proceedings of ACL.</p>

<p>[6] <a href="http://research.microsoft.com/en-us/projects/dssm/">MSR <strong>DSSM</strong></a> 系列：</p>

<p>[Huang, He, Gao, Deng, Acero, Heck, CIKM2013] </p>

<p>[Shen, He, Gao, Deng, Mesnil, WWW2014] </p>

<p>[Gao, He, Yih, Deng, ACL2014] </p>

<p>[Yih, He, Meek, ACL2014] </p>

<p>[Song, He, Gao, Deng, Shen, MSR-TR 2014] </p>

<p>[Gao, Pantel, Gamon, He, Deng, Shen, EMNLP2014] </p>

<p>[Shen, He, Gao, Deng, Mesnil, CIKM2014] </p>

<p>[He, Gao, Deng, ICASSP2014 Tutorial] </p>

<p>[Liu, Gao, He, NAACL2015] 
[Gao, He, Deng, MSR-TR-2015]</p>

<p>[7] Siyu Qiu, Qing Cui, Jiang Bian, Bin Gao, and Tie-Yan Liu. 2014. <strong>Co-learning of Word Representations and Morpheme Representations</strong>. COLING.</p>

<p><strong>（3）contexts</strong> </p>

<p><img src="/images/MultipleVectorWordEmbedding_bg.png" alt="result of Socher's dependency-based word embeddings" /></p>

<p>既然单纯的 context 可以认为是有用的，也可以被认为是不足的。除了固定 window size 内的上下文 contexts words 信息，还有什么可以用的信息呢？这样的考虑下，又带来了两种不同的改进。一种是直接替换掉 contexts words，用其他 enriched information words，比如 modifier-dependency-label pairs，比如 related word pairs（比如 WordNet 里那些 synonymy words）。另一种就是直接在 local contexts（即 window size 内的 context）的基础上，结合进 global contexts 或者其他 additional information。这种结合多数是线性 combine 进另一个神经网络，首创的就是 Huang et al., 2012 年的非常重要的论文。其他相关改变 contexts 的文章有：</p>

<p>[8] Eric H. Huang, Richard Socher, Christopher D. Manning, Andrew Y. Ng. 2012. <strong>Improving Word Representations via Global Context and Multiple Word Prototypes</strong>. ACL.</p>

<p>[9] Asli Celikyilmaz, Dilek Hakkani-Tur, Panupong Pasupat, and Ruhi Sarikaya. 2015.  <strong>Enriching Word Embeddings Using Knowledge Graph for Semantic Tagging in Conversational Dialog Systems</strong>. AAAI.</p>

<p>[10] Mo Yu and Dredze. 2014. <strong>Improving Lexical Embeddings with Semantic Knowledge</strong>. ACL.</p>


      <footer class="entry-meta">
        <span class="entry-tags"><a href="/tags/#deep learning" title="Pages tagged deep learning" class="tag">deep learning</a><a href="/tags/#natural language processing" title="Pages tagged natural language processing" class="tag">natural language processing</a><a href="/tags/#representaion" title="Pages tagged representaion" class="tag">representaion</a><a href="/tags/#word2vec" title="Pages tagged word2vec" class="tag">word2vec</a><a href="/tags/#paper" title="Pages tagged paper" class="tag">paper</a></span>
        <span><a href="/peppypapers/2015/05/23/Adapations-and-Variations-of-Word2Vec.html" rel="bookmark" title="Adapations and Variations of Word2vec">Adapations and Variations of Word2vec</a> was published on <span class="entry-date date published updated"><time datetime="2015-05-23T00:00:00+08:00">May 23, 2015</time></span></span>
        
        <span class="author vcard"><span class="fn"><a href="/about/" title="About Maggie">Maggie</a></span></span>
        <div class="social-share">
          <ul class="socialcount socialcount-small inline-list">
            <li class="facebook"><a href="https://www.facebook.com/sharer/sharer.php?u=/peppypapers/2015/05/23/Adapations-and-Variations-of-Word2Vec.html" title="Share on Facebook"><span class="count"><i class="icon-facebook-sign"></i> Like</span></a></li>
            <li class="twitter"><a href="https://twitter.com/intent/tweet?text=/peppypapers/2015/05/23/Adapations-and-Variations-of-Word2Vec.html" title="Share on Twitter"><span class="count"><i class="icon-twitter-sign"></i> Tweet</span></a></li>
            <li class="googleplus"><a href="https://plus.google.com/share?url=/peppypapers/2015/05/23/Adapations-and-Variations-of-Word2Vec.html" title="Share on Google Plus"><span class="count"><i class="icon-google-plus-sign"></i> +1</span></a></li>
          </ul>
        </div><!-- /.social-share -->
      </footer>
    </div><!-- /.entry-content -->
    
    
    <div class="read-more">
      
        <div class="read-more-header">
          <a href="/peppypapers/2015/05/03/Improving-Word-Representations-via-Global-Context-and-Multiple-Word-Prototypes.html" class="read-more-btn">Read More</a>
        </div><!-- /.read-more-header -->
        <div class="read-more-content">
          <h3><a href="/resource/2015/06/05/datasets.html" title="Datasets">Datasets</a></h3>
          <p>Here are some selected datasets commonly used in Machine Learning related tasks, for further automatical machine learning framework.**Git...&hellip; <a href="/resource/2015/06/05/datasets.html">Continue reading</a></p>
        </div><!-- /.read-more-content -->
      
      <div class="read-more-list">
        
          <div class="list-item">
            <h4><a href="/peppypapers/2015/05/03/Improving-Word-Representations-via-Global-Context-and-Multiple-Word-Prototypes.html" title="Improving Word Representations via Global Context and Multiple Word Prototypes">Improving Word Representations via Global Context and Multiple Word Prototypes</a></h4>
            <span>Published on May 03, 2015</span>
          </div><!-- /.list-item -->
        
          <div class="list-item">
            <h4><a href="/peppypapers/2015/04/18/DeepWalk-Online-Learning-of-Social-Representations.html" title="DeepWalk Online Learning of Social Representations">DeepWalk Online Learning of Social Representations</a></h4>
            <span>Published on April 18, 2015</span>
          </div><!-- /.list-item -->
        
      </div><!-- /.read-more-list -->
      
    </div><!-- /.read-more -->
  </article>
</div><!-- /#main -->

<div class="footer-wrapper">
  <footer role="contentinfo">
    <span>&copy; 2015 Maggie. Powered by <a href="http://jekyllrb.com">Jekyll</a> using the <a href="http://mademistakes.com/hpstr/">HPSTR Theme</a>.</span>
  </footer>
</div><!-- /.footer-wrapper -->

<script src="//ajax.googleapis.com/ajax/libs/jquery/1.9.1/jquery.min.js"></script>
<script>window.jQuery || document.write('<script src="/assets/js/vendor/jquery-1.9.1.min.js"><\/script>')</script>
<script src="/assets/js/scripts.min.js"></script>

<script type="text/javascript">
    /* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
    var disqus_shortname = ''; // required: replace example with your forum shortname

    /* * * DON'T EDIT BELOW THIS LINE * * */
    (function() {
        var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
        dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();

    /* * * DON'T EDIT BELOW THIS LINE * * */
    (function () {
        var s = document.createElement('script'); s.async = true;
        s.type = 'text/javascript';
        s.src = '//' + disqus_shortname + '.disqus.com/count.js';
        (document.getElementsByTagName('HEAD')[0] || document.getElementsByTagName('BODY')[0]).appendChild(s);
    }());
</script>
<noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="http://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>	        

</body>
</html>
